{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1IhSV4-OYyR"
      },
      "source": [
        "# Week 10: Sentiment Analysis\n",
        "\n",
        "Our task this week is as follows:\n",
        "* Get to know Python dictionaries\n",
        "* Learn about sentiment analysis, and learn how to use the sentiment analysis package in TextBlob\n",
        "* Discuss limitations of lexicon-based approach and look at how we can overcome some of them\n",
        "* Perform a small \"who wore it better\" competition between TextBlob with VADER (algorithm audit)\n",
        "* Load a novel into a dataframe, sentence by sentence.\n",
        "* Record the sentiment values for each sentence in that dataframe\n",
        "* Extract the sentences identified as the \"happiest\" and the \"saddest\" by the sentiment analysis system"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUF2OpiRESj_"
      },
      "source": [
        "## Python Dictionaries\n",
        "\n",
        "Before we get to sentiment analysis, we need to introduce another Python data type, which arguably can be a faviourite for English majors: dictionaries\n",
        "\n",
        "As [Melanie Walsh explains](https://melaniewalsh.github.io/Intro-Cultural-Analytics/02-Python/11-Dictionaries.html), dictionaries are mainly differentiated from `list`s by their use of **key-value pairs**. Whereas we access items in a list by their index position, we access the **values** of items in a dictionary by their **key**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuXq2hmtErfD"
      },
      "source": [
        "Python dictionaries are always surrounded by curly brackets `{ }`. You can make a dictionary in this manner:\n",
        "\n",
        "```\n",
        "variable_name = {\n",
        "   'key1': value1,\n",
        "   'key2': value2,\n",
        "   'key3': value3,\n",
        "}\n",
        "```\n",
        "Note:\n",
        "- Keys are `string`s; values can be of any data type.\n",
        "- Note that a `,` comes between each key-value pair your define\n",
        "- You don't need to arrange things like this typographically, with key-values pairs each on their own line, but it does make things look prettier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGpK8XdSE5U6"
      },
      "source": [
        "Some examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xocUqUNNE3W7"
      },
      "outputs": [],
      "source": [
        "# writers is a dictionary where the keys are names of writers, and the values \n",
        "# are the year of their birth\n",
        "writers = {\n",
        "    \"William Shakespeare\": 1564,\n",
        "    \"Jane Austen\": 1775,\n",
        "    \"Leo Tolstoy\": 1828,\n",
        "    \"Gabriel Garcia Marquez\": 1927,\n",
        "    \"Margaret Atwood\": 1939,\n",
        "}\n",
        "\n",
        "print(writers[\"William Shakespeare\"])\n",
        "\n",
        "writers[\"Virginia Woolf\"] = 1882 #adding a new key-value pair to a dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PqsUUjIFt4E"
      },
      "outputs": [],
      "source": [
        "# writers is a dictionary where the keys are names of writers, and the values \n",
        "# are a list containing their year of birth and their year of death\n",
        "writers = {\n",
        "    \"William Shakespeare\": [1564, 1616],\n",
        "    \"Jane Austen\": [1775, 1817],\n",
        "    \"Leo Tolstoy\": [1828, 1910],\n",
        "    \"Gabriel Garcia Marquez\": [1927, 2014],\n",
        "    \"Margaret Atwood\": [1939, None],\n",
        "    \"Virginia Woolf\": [1882, 1941]\n",
        "}\n",
        "writers[\"Margaret Atwood\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31NM79PxG_hV"
      },
      "outputs": [],
      "source": [
        "# Create a list of the writers from the 20th century\n",
        "writers_in_20th_century = []\n",
        "\n",
        "# for each KEY in writers\n",
        "for writer in writers: \n",
        "    birth_year = writers[writer][0]\n",
        "    death_year = writers[writer][1]\n",
        "    #birth_year, death_year = writers[writer] #alternative way\n",
        "    still_alive =  death_year is None\n",
        "    if (birth_year <= 2000 and (still_alive or death_year >= 1901)):\n",
        "        writers_in_20th_century.append(writer)\n",
        "\n",
        "writers_in_20th_century"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let's write a function that returns a list of writers from the 20th century\n",
        "\n",
        "def get_writers_in_20th_century(writer_list):\n",
        "    result = []\n",
        "    for writer in writer_list: \n",
        "        birth_year = writer_list[writer][0]\n",
        "        death_year = writer_list[writer][1]\n",
        "\n",
        "        still_alive =  death_year is None\n",
        "        if (birth_year <= 2000 and (still_alive or death_year >= 1901)):\n",
        "            result.append(writer)\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_writers = get_writers_in_20th_century(writers)\n",
        "print(new_writers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSILvC4MHpe4"
      },
      "outputs": [],
      "source": [
        "# A dictionary where the keys are names of authors, and the values\n",
        "# are dictionaries.\n",
        "writers = {\n",
        "    \"William Shakespeare\": {\n",
        "        \"country\": \"England\",\n",
        "        \"birth_year\": 1564,\n",
        "        \"death_year\": 1616\n",
        "    },\n",
        "    \"Jane Austen\": {\n",
        "        \"country\": \"England\",\n",
        "        \"birth_year\": 1775,\n",
        "        \"death_year\": 1817\n",
        "    },\n",
        "    \"Leo Tolstoy\": {\n",
        "        \"country\": \"Russia\",\n",
        "        \"birth_year\": 1828,\n",
        "        \"death_year\": 1910\n",
        "    },\n",
        "    \"Gabriel Garcia Marquez\": {\n",
        "        \"country\": \"Colombia\",\n",
        "        \"birth_year\": 1927,\n",
        "        \"death_year\": 2014\n",
        "    },\n",
        "    \"Margaret Atwood\": {\n",
        "        \"country\": \"Canada\",\n",
        "        \"birth_year\": 1939,\n",
        "        \"death_year\": None  # Still living\n",
        "    },\n",
        "    \"Virginia Woolf\": {\n",
        "        \"country\": \"England\",\n",
        "        \"birth_year\": 1882,\n",
        "        \"death_year\": 1941\n",
        "    }\n",
        "}\n",
        "\n",
        "writers[\"Gabriel Garcia Marquez\"][\"country\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wi0yqWViOYyt"
      },
      "source": [
        "## Iterating Through Dictionaries\n",
        "\n",
        "You can iterate through dictionaries — but first you need to specify, by calling the appropriate method, if you want to iterate over keys, values, of key-value pairs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Pr3hrQ5ZK3E"
      },
      "outputs": [],
      "source": [
        "carnivores = {\n",
        "    \"python\": \"A large heavy-bodied nonvenomous snake that kills poor prey by constriction and asphyxiation\",\n",
        "    \"panda\": \"A large bearlike mammal that, while technically a carnivore, is in practice a vegetarian, eating only bamboo\",\n",
        "    \"kitten\": \"A delightful, fuzzy creature whose natural prey is cat food (dry or wet) and, especially, treats\"\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0U1SraiVHYnF"
      },
      "source": [
        "Adding a new key-value pair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LuVLmiNHGQ_"
      },
      "outputs": [],
      "source": [
        "carnivores[\"blob\"] = \"A third-party Python library that slowly kills you by sucking up all of your time, because the textual analysis it facilitates is so fascinating\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J58tLPAJzkkY"
      },
      "source": [
        "We can loop through KEYS (two ways)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rwgexs-ZVyF"
      },
      "outputs": [],
      "source": [
        "for key in carnivores:\n",
        "    print(f\"I am so afraid of {key.upper()}S!!!!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEeEB75KOYyt"
      },
      "outputs": [],
      "source": [
        "for key in carnivores.keys():\n",
        "    print(f\"I am so afraid of {key.upper()}S!!!!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9I754luZz1Ej"
      },
      "source": [
        "That, of course, allows us to do something with values as well"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5nT9J51zr_r"
      },
      "outputs": [],
      "source": [
        "for creature in carnivores:\n",
        "    print(f\"Why I am so afraid of {creature}s?\")\n",
        "    print(f\"Because {creature} is {carnivores[creature].lower()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LW7RTS000UAq"
      },
      "source": [
        "Or we can loop through values directly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myoW4Hn6OYyu"
      },
      "outputs": [],
      "source": [
        "for value in carnivores.values():\n",
        "    print(f\"Did you know there is a kind of carnivore that is {value}???\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVthxfFE0Ykc"
      },
      "source": [
        "Difficult to remember at first, but there is a useful bit of Python syntax called unpacking, which we can rely on to loop through both keys and values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3NIY-xUOYyu",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "for key, value in carnivores.items():\n",
        "    print(f\"A {key} is {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TiWsBadIFWj"
      },
      "source": [
        "# Sentiment Analysis. Part I"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROy9ahkqk4In"
      },
      "source": [
        "Sentiment analysis is the task of determining the emotional content of an expression (sequence of words) in natural language.\n",
        "\n",
        "We will\n",
        "- show (and use) the simplest version of approaching sentiment analysis -- bag-of-words lexicon-based approach\n",
        "- briefly discuss what are the main disadvantages\n",
        "- discuss the main heuristics we can apply to critically analyze algorithms\n",
        "- look how we can improve on the simplest version and how to assess if it works well\n",
        "\n",
        "We are using two new Python libraries that implement lots of functions related to sentiment analysis and other natural language processing tasks.  In fact, nltk stands for natural language took kit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q85f82BC3tM0"
      },
      "source": [
        "We also employ a subset of an approach called \"algorithmic audit\" trying to critically evaluate what the algorithm does, what is it (not) good for, what are the biases -- think about the questions we have for datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJ_Hz1lzGts7"
      },
      "outputs": [],
      "source": [
        "!pip install textblob\n",
        "!pip install nltk\n",
        "!pip install wordcloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KftT6ot2GLk"
      },
      "outputs": [],
      "source": [
        "from textblob import TextBlob\n",
        "import nltk\n",
        "\n",
        "blob = TextBlob(carnivores[\"panda\"])\n",
        "print(blob)\n",
        "print(f\"Polarity {blob.sentiment.polarity}\")\n",
        "print(f\"Subjectivity {blob.sentiment.subjectivity}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4UfPehP4I__"
      },
      "outputs": [],
      "source": [
        "blob = TextBlob(carnivores[\"python\"])\n",
        "print(blob)\n",
        "print(f\"Polarity {blob.sentiment.polarity}\")\n",
        "print(f\"Subjectivity {blob.sentiment.subjectivity}\")\n",
        "\n",
        "blob = TextBlob(carnivores[\"kitten\"])\n",
        "print(blob)\n",
        "print(f\"Polarity {blob.sentiment.polarity}\")\n",
        "print(f\"Subjectivity {blob.sentiment.subjectivity}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ud6SbFP74cfi"
      },
      "source": [
        "Word-based approach to sentiment analysis assigns some numeric score (positive or negative) to the word. And sums/averages over the word scores.\n",
        "\n",
        "Let's audit how this would work on the examples for which we know/can think of the answers!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P02GcE-u3T8R"
      },
      "outputs": [],
      "source": [
        "print(TextBlob(\"awful\").sentiment.polarity)\n",
        "print(TextBlob(\"great\").sentiment.polarity)\n",
        "print(TextBlob(\"window\").sentiment.polarity)\n",
        "print(TextBlob(\"not great\").sentiment.polarity)\n",
        "print(TextBlob(\"not so great\").sentiment.polarity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkHksLRg4Lf_"
      },
      "source": [
        "- What other cases you can think of when this approach could fail?\n",
        "- When it might be good enough?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ryB58HjOYyU"
      },
      "source": [
        "The [documentation for TextBlob](https://textblob.readthedocs.io/en/dev/) isn't the best, but the default sentiment system is based on a tool called [pattern](https://github.com/clips/pattern), which employs a sentiment lexicon — a list of words with values, many of them hand-coded.\n",
        "- You can see the source code [here](https://github.com/sloria/TextBlob/blob/6396e24e85af7462cbed648fee21db5082a1f3fb/textblob/en/__init__.py#L8) (around line 80): it basically averages the sentiment scores for the all the words in the span, and applies some rule-based heuristics to identify negations.\n",
        "- You can see the full lexicon [here](https://github.com/sloria/TextBlob/blob/6396e24e85af7462cbed648fee21db5082a1f3fb/textblob/en/__init__.py#L8); it's mostly adjective-based."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBeENwp_OYyV"
      },
      "outputs": [],
      "source": [
        "from textblob import TextBlob\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAj6WIiLOYyW"
      },
      "outputs": [],
      "source": [
        "TextBlob(\"Neil Young is the greatest artist to come out of this country\").sentiment.polarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGNWCH5YOYyY"
      },
      "outputs": [],
      "source": [
        "TextBlob(\"I hate Neil Young and his stupid, whiny voice\").sentiment.polarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdLUM4leOYyY"
      },
      "outputs": [],
      "source": [
        "TextBlob(\"Sometimes I feel like Neil Young is the greatest singer of his generation\").sentiment.polarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hd9OTbviOYyZ"
      },
      "outputs": [],
      "source": [
        "TextBlob(\"Neil Young isn’t the worst Canadian musician\").sentiment.polarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_OAEm3DOYya"
      },
      "outputs": [],
      "source": [
        "TextBlob(\"Oh yeah, Neil Young’s voice is as lovely as Josh Groban’s\").sentiment.polarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jBePMBJOYya"
      },
      "outputs": [],
      "source": [
        "TextBlob(\"Hating on amazing music isn’t something I’m known for\").sentiment.polarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbLQ9Mn7OYyb"
      },
      "outputs": [],
      "source": [
        "TextBlob(\"Neil Young\").sentiment.polarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Gck-SWmOYyf"
      },
      "source": [
        "The way we work with TextBlob is first by \"blobbing\" a string of text (aka, turning it from a string to a TextBlob object). This is done by passing the string as argument to the `TextBlob` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_QnN3jjOYyf"
      },
      "outputs": [],
      "source": [
        "text = \"A blob is A third-party Python library that slowly kills you by sucking up all of your time, because the textual analysis it facilitates is so fascinating\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TK2XO7HpOYyf"
      },
      "outputs": [],
      "source": [
        "definition_blob = TextBlob(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRGN8XPnOYyf"
      },
      "outputs": [],
      "source": [
        "type(definition_blob)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5fFv4yeOYyg"
      },
      "source": [
        "## Using TextBlob to Tokenize Strings and Split Them Into Sentences\n",
        "\n",
        "Once a text is blobbed, we can start calling the special TextBlob methods on it. Note that TextBlob methods don't take arguments, and indeed don't even have the usual method syntax of being followed by `()` — which I personally find a bit ugly.\n",
        "\n",
        "Let's look at two to start with:\n",
        "- `blob.words`: This tokenizes the string, turning into words. We've been accomplishing this with Python's built-in `string.split()` for many weeks now, then doing some extra stuff like removing punctuation with regular expressions. TextBlob does it all in one fell swoop, and does a good job with it — although we get less control over the process, and I personally prefer our previous method (can you see why??). The object it returns behaves like a `list`.\n",
        "- `blob.sentences`: This returns all the sentences in a string. We've been accomplishing this with `string.split(\".\")`. This does exactly the same thing, from what I can tell; for instance, it isn't smart enough to also split on `?` or `!`, and it is just as confused by contractions like `per cent.`. The object it returns again behaves like a `list`'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnopb6KCOYyg"
      },
      "outputs": [],
      "source": [
        "definition_blob.words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0UU-uUuOYyg"
      },
      "outputs": [],
      "source": [
        "type(definition_blob.words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdF6cjcBOYyh"
      },
      "outputs": [],
      "source": [
        "definition_blob.words[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAA5V2mMOYyh"
      },
      "outputs": [],
      "source": [
        "for word in definition_blob.words:\n",
        "    print(word.upper())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNJXbqcVOYyh"
      },
      "outputs": [],
      "source": [
        "sot4 = open(\"sign-of-four.txt\", encoding=\"utf-8\").read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VdS8xhz2OYyn"
      },
      "outputs": [],
      "source": [
        "sot4_blob = TextBlob(sot4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9c8W_p1HOYyn"
      },
      "outputs": [],
      "source": [
        "sot4_blob.words[255:269]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4uO68E5OYyo"
      },
      "outputs": [],
      "source": [
        "sot4_blob.sentences[9:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5FqBAzNOYyo"
      },
      "source": [
        "### TextBlob Word Counts... and Python Dictionaries\n",
        "\n",
        "TextBlob has another use method, `blob.word_counts`, which returns a list of the most commonly used terms in a document, along with a count for each of those words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snCw7Q6UOYyo"
      },
      "outputs": [],
      "source": [
        "definition_blob.word_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjMIpT6MOYyo"
      },
      "outputs": [],
      "source": [
        "sot4_blob.word_counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42oe72K7OYyo"
      },
      "source": [
        "**Python data type** returned by the `blob.words_counts` method — well, that's not a `list` at all, but rather a **dictionary (`dict`)**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szg3iSPqOYyu"
      },
      "outputs": [],
      "source": [
        "sot4_counts = sot4_blob.word_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WA1b1q5rOYyu"
      },
      "outputs": [],
      "source": [
        "type(sot4_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NBun8OMOYyu"
      },
      "outputs": [],
      "source": [
        "sot4_counts['cocaine']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqLFqn0VOYyv"
      },
      "source": [
        "By the way, since `blob.word_counts` produces a dictionary-like object in which each key is a unique word... can you tell me the one-line command we could use use to calculate the TTR of any TextBlob object?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-niK-ZZGOYyv"
      },
      "outputs": [],
      "source": [
        "# We'll figure this one out together...\n",
        "# we need the number of unique tokens and the total number of tokens.  How can we get that from the dictionary?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThrkAeTSOYyv"
      },
      "source": [
        "# Sentiment Analysis in TextBlob\n",
        "\n",
        "Okay, it's finally time to get back to the thing we really want to do in TextBlob: use its sentiment analysis package for literature!\n",
        "\n",
        "This is accessible with the `blob.sentiment`, `blob.sentiment.polarity`, and `blob.sentiment.subjectivity` methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnSkpKn5OYyv"
      },
      "outputs": [],
      "source": [
        "definition_blob.sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XFqMv0mOYyw"
      },
      "outputs": [],
      "source": [
        "definition_blob.sentiment.polarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcfjX5RCOYyw"
      },
      "outputs": [],
      "source": [
        "definition_blob.sentiment.subjectivity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4XESgRPOYyw"
      },
      "source": [
        "Today we are going to focus on sentiment polarity today (how positive or negative, happy or sad, a particular span of text is."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxr1yIXpOYyx"
      },
      "source": [
        "## Creating a DataFrame of Polarity Values for *The Sign of the Four*\n",
        "\n",
        "We now have pretty much all the pieces in place to accomplish our task: creating a DataFrame in which each row contains a sentence from *The Sign of the Four* and the TextBlob polarity and subjectivity score for that sentence. Let's go!\n",
        "\n",
        "We will create three parallel lists:\n",
        "- one containing the text of every sentence, in the form of a `string`\n",
        "- one containing a polarity value for each sentence, in the form of a `float`\n",
        "- one containing a subjectivity value for each sentence, also in the form of a `float`\n",
        "\n",
        "How would we do this, using skills we learned back in the first half of the course?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXxCidM5OYyy"
      },
      "source": [
        "### Using `blob.sentences`\n",
        "\n",
        "Let's start by examining the output of TextBlob's `blob.sentences` method more closely, so we get a better sense of how we'll produce our three desired lists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Re36jN6AOYyy"
      },
      "outputs": [],
      "source": [
        "sot4_sentences_blob = sot4_blob.sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0et4DRvOYyy"
      },
      "outputs": [],
      "source": [
        "type(sot4_sentences_blob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "975wG44IOYyy"
      },
      "outputs": [],
      "source": [
        "sot4_sentences_blob[22]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rShRSOXEOYyy"
      },
      "outputs": [],
      "source": [
        "type(sot4_sentences_blob[22])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJk13AM4OYyy"
      },
      "outputs": [],
      "source": [
        "sot4_sentences_blob[22].sentiment.polarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsrFuavWOYyz"
      },
      "outputs": [],
      "source": [
        "sot4_polarities = []\n",
        "\n",
        "for sentence in sot4_sentences_blob:\n",
        "    sot4_polarities.append(sentence.sentiment.polarity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGPACsh7OYyz"
      },
      "outputs": [],
      "source": [
        "sot4_polarities[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtwnXSK9OYyz"
      },
      "outputs": [],
      "source": [
        "sot4_subjectivities = []\n",
        "\n",
        "for sentence in sot4_sentences_blob:\n",
        "    sot4_subjectivities.append(sentence.sentiment.subjectivity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-veyy0RIOYyz"
      },
      "outputs": [],
      "source": [
        "sot4_subjectivities[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RD4Ga2PfOYyz"
      },
      "outputs": [],
      "source": [
        "sot4_sentences_blob[22]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMqL61E8OYy0",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "sot4_sentences_blob[22].raw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWcdKBvQOYy0",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "type(sot4_sentences_blob[22].raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xp1g9DaZOYy0"
      },
      "outputs": [],
      "source": [
        "sot4_sentences_blob[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iSHJ2UXOYy0"
      },
      "outputs": [],
      "source": [
        "sot4_sentences_blob[0].raw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7G-oUT_zOYy1"
      },
      "source": [
        "Since that output is a bit ugly, with all those `\\n\\n\\n`s, let's create our `string` of each sentence in a slightly different way: by using Python's `string.join()` method, which we met wayyyyy back in Week 3 (go look if you don't believe me!).\n",
        "\n",
        "Here, we'll use `string.join()` to join together all the `blob.word`s with spaces, which gives us a pretty string to work with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9AlyWWjOYy1"
      },
      "outputs": [],
      "source": [
        "sot4_sentences_blob[0].words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxbrd59vOYy1"
      },
      "outputs": [],
      "source": [
        "\" \".join(sot4_sentences_blob[0].words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pe3FHuhfOYy1"
      },
      "outputs": [],
      "source": [
        "type(\" \".join(sot4_sentences_blob[0].words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9JI_5F9OYy2"
      },
      "outputs": [],
      "source": [
        "sot4_sentences = []\n",
        "\n",
        "for sentence in sot4_sentences_blob:\n",
        "    sot4_sentences.append(\" \".join(sentence.words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKf01ek8OYy2"
      },
      "outputs": [],
      "source": [
        "sot4_sentences[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIThYv65OYy2"
      },
      "source": [
        "### Creating a DataFrame from Three Parallel Lists\n",
        "\n",
        "Okay, we have all the contents of our desired DataFrame.\n",
        "\n",
        "- A list containing all the sentences of *The Sign of the Four*, in order\n",
        "- A list containing the polarity values for each of those sentences, in order\n",
        "- A list containing the subjectivity values for each of those sentences, in order"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRWU4Y8POYy2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAytjZKJOYy2"
      },
      "outputs": [],
      "source": [
        "sot4_sentence_sentiment_df = pd.DataFrame({\n",
        "    'sentence': sot4_sentences,\n",
        "    'polarity': sot4_polarities,\n",
        "    'subjectivity': sot4_subjectivities\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRHbz-BjOYy3"
      },
      "outputs": [],
      "source": [
        "sot4_sentence_sentiment_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMYJiCm2OYy3"
      },
      "source": [
        "Let's now have a look at the sentences that TextBlob considers the most positive, as well as the most negative ones..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVIIFKgOOYy3"
      },
      "outputs": [],
      "source": [
        "sot4_sentence_sentiment_df.sort_values(by='polarity', ascending=False)[:15]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdWf86CrOYy3"
      },
      "source": [
        "Pretty hard to read what's in the `Sentence` column! We could export it to a CSV and explore it in Excel or Google Sheets... or we can set this Pandas parameter so that there is no maximum column width, and it will just show us everything!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INuEBsM7OYy3"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_colwidth', 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyMU62dZOYy3"
      },
      "outputs": [],
      "source": [
        "sot4_sentence_sentiment_df.sort_values(by='polarity', ascending=False)[:15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7razxciOYy4",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "sot4_sentence_sentiment_df.sort_values(by='polarity', ascending=True)[:15]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Word cloud\n",
        "\n",
        "Here is some code to create a word cloud.  This might be something useful for your project, or it might just be a fun visualization exercize.\n",
        "\n",
        "This result for The Sign of Four isn't very interesting, but if you were doing something with shorter texts like songs, poems, reviews, social media messages a word cloud miht be more interesting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud, ImageColorGenerator, STOPWORDS\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# \n",
        "stop_words = set(stopwords.words('english'))\n",
        "words_filtered = []\n",
        "\n",
        "for w in sot4_blob.words:\n",
        "    if w not in stop_words and w.isalpha():\n",
        "        words_filtered.append(w)\n",
        "\n",
        "text = \" \".join([ele for ele in words_filtered])\n",
        "word_cloud = WordCloud(background_color=\"white\", random_state=1,stopwords=stop_words,max_words=100,width =800, height = 1500)\n",
        "word_cloud.generate(text)\n",
        "plt.figure(figsize=[10,10])\n",
        "plt.imshow(word_cloud,interpolation=\"bilinear\")\n",
        "plt.axis('off')\n",
        "plt.savefig('foo.png')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
